{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, matthews_corrcoef\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import MobileBertTokenizer, MobileBertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import SqueezeBertTokenizer, SqueezeBertForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training.csv')\n",
    "df_val = pd.read_csv('validation.csv')\n",
    "df_test = pd.read_csv('testing.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model you wish to train\n",
    "\n",
    "model_name = \n",
    "\n",
    "# 'albert-base-v2'\n",
    "# \"bert-base-uncased\"\n",
    "# \"vinai/bertweet-base\"\n",
    "# \"distilbert-base-uncased\"\n",
    "# 'google/mobilebert-uncased'\n",
    "# \"roberta-base\"\n",
    "# 'squeezebert/squeezebert-uncased'\n",
    "\n",
    "# Select the appropriate Tokeniser WRT to the model chosen. E.g here we load the ALBERT tokenizer for the ALBERT model\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Select the appropriate model initialiser WRT to the model chosen. E.g here we load AlbertForSequenceClassification for the ALBERT model\n",
    "\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 1. Preprocess data -----#\n",
    "# Preprocess data\n",
    "\n",
    "X_train = list(df_train[\"text\"])\n",
    "y_train = list(df_train[\"label\"])\n",
    "\n",
    "X_val = list(df_val[\"text\"])\n",
    "y_val = list(df_val[\"label\"])\n",
    "\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch data set\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation torch data sets \n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to log during training\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average = 'weighted')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average = 'weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"######\",   # Where you wish to checkpoint each model at certain steps\n",
    "    evaluation_strategy=\"steps\", # When to do the evaluation\n",
    "    eval_steps=50, # How often to do the evaluation\n",
    "    logging_steps = 50, # How often logging must occur\n",
    "    per_device_train_batch_size=16, # training batch size\n",
    "    per_device_eval_batch_size=16, # evaluation batch size\n",
    "    num_train_epochs=2, # Number of epochs\n",
    "    seed=0, \n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",  # Enable logging to Weights and Biases\n",
    "    run_name=\"albert\"  # name of the Weights and Biases run\n",
    ")\n",
    "\n",
    "# Initialise the trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data and tokenise it\n",
    "\n",
    "X_test = list(df_test['text'])\n",
    "y_test = list(df_test['label'])\n",
    "\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset for the test data\n",
    "test_dataset = Dataset(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = \"#####\" # Load the best model from your directory\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_path, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test trainer\n",
    "test_trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the rest data set\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred) # Confusion matrix for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred)) # Classification report for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
